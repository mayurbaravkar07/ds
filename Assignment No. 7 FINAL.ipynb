{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbdc966",
   "metadata": {},
   "source": [
    "7) Text Analytics\n",
    "1. Extract Sample document and apply following document preprocessing methods:\n",
    "Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "2. Create representation of documents by calculating Term Frequency and Inverse\n",
    "DocumentFrequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799a5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "text='The Moon is a barren, rocky world without air and water. It has dark lava plain on its surface. The Moon is filled wit craters. It has no light of its own. It gets its light from the Sun. The Moo keeps changing its shape as it moves round the Earth. It spins on its axis in 27.3 days stars were named after the Edwin Aldrin were the first ones to set their foot on the Moon on 21 July 1969 They reached the Moon in their space craft named Apollo II.'\n",
    "text=text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be2c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token=nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18df052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'a',\n",
       " 'barren',\n",
       " ',',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'and',\n",
       " 'water',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'on',\n",
       " 'its',\n",
       " 'surface',\n",
       " '.',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'is',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " '.',\n",
       " 'it',\n",
       " 'has',\n",
       " 'no',\n",
       " 'light',\n",
       " 'of',\n",
       " 'its',\n",
       " 'own',\n",
       " '.',\n",
       " 'it',\n",
       " 'gets',\n",
       " 'its',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sun',\n",
       " '.',\n",
       " 'the',\n",
       " 'moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'its',\n",
       " 'shape',\n",
       " 'as',\n",
       " 'it',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'the',\n",
       " 'earth',\n",
       " '.',\n",
       " 'it',\n",
       " 'spins',\n",
       " 'on',\n",
       " 'its',\n",
       " 'axis',\n",
       " 'in',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'were',\n",
       " 'named',\n",
       " 'after',\n",
       " 'the',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'were',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'to',\n",
       " 'set',\n",
       " 'their',\n",
       " 'foot',\n",
       " 'on',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'on',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'they',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'moon',\n",
       " 'in',\n",
       " 'their',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac4749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token=nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18dde202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the moon is a barren, rocky world without air and water.',\n",
       " 'it has dark lava plain on its surface.',\n",
       " 'the moon is filled wit craters.',\n",
       " 'it has no light of its own.',\n",
       " 'it gets its light from the sun.',\n",
       " 'the moo keeps changing its shape as it moves round the earth.',\n",
       " 'it spins on its axis in 27.3 days stars were named after the edwin aldrin were the first ones to set their foot on the moon on 21 july 1969 they reached the moon in their space craft named apollo ii.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad637f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vishakha/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopword=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a7d22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67554e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "removing_stopwords=[word for word in word_token if word not in stopword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e50317f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moon',\n",
       " 'barren',\n",
       " ',',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'water',\n",
       " '.',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'surface',\n",
       " '.',\n",
       " 'moon',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'craters',\n",
       " '.',\n",
       " 'light',\n",
       " '.',\n",
       " 'gets',\n",
       " 'light',\n",
       " 'sun',\n",
       " '.',\n",
       " 'moo',\n",
       " 'keeps',\n",
       " 'changing',\n",
       " 'shape',\n",
       " 'moves',\n",
       " 'round',\n",
       " 'earth',\n",
       " '.',\n",
       " 'spins',\n",
       " 'axis',\n",
       " '27.3',\n",
       " 'days',\n",
       " 'stars',\n",
       " 'named',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'first',\n",
       " 'ones',\n",
       " 'set',\n",
       " 'foot',\n",
       " 'moon',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'reached',\n",
       " 'moon',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removing_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1fc4cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/vishakha/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "wordnet_lemmatizer=WordNetLemmatizer()\n",
    "lemmatized_word=[wordnet_lemmatizer.lemmatize(word) for word in removing_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "590486f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moon',\n",
       " 'barren',\n",
       " ',',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'water',\n",
       " '.',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'surface',\n",
       " '.',\n",
       " 'moon',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'crater',\n",
       " '.',\n",
       " 'light',\n",
       " '.',\n",
       " 'get',\n",
       " 'light',\n",
       " 'sun',\n",
       " '.',\n",
       " 'moo',\n",
       " 'keep',\n",
       " 'changing',\n",
       " 'shape',\n",
       " 'move',\n",
       " 'round',\n",
       " 'earth',\n",
       " '.',\n",
       " 'spin',\n",
       " 'axis',\n",
       " '27.3',\n",
       " 'day',\n",
       " 'star',\n",
       " 'named',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'first',\n",
       " 'one',\n",
       " 'set',\n",
       " 'foot',\n",
       " 'moon',\n",
       " '21',\n",
       " 'july',\n",
       " '1969',\n",
       " 'reached',\n",
       " 'moon',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed71f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer=SnowballStemmer('english')\n",
    "stemmed_word=[snowball_stemmer.stem(word) for word in lemmatized_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3a1b176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moon',\n",
       " 'barren',\n",
       " ',',\n",
       " 'rocki',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'water',\n",
       " '.',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'surfac',\n",
       " '.',\n",
       " 'moon',\n",
       " 'fill',\n",
       " 'wit',\n",
       " 'crater',\n",
       " '.',\n",
       " 'light',\n",
       " '.',\n",
       " 'get',\n",
       " 'light',\n",
       " 'sun',\n",
       " '.',\n",
       " 'moo',\n",
       " 'keep',\n",
       " 'chang',\n",
       " 'shape',\n",
       " 'move',\n",
       " 'round',\n",
       " 'earth',\n",
       " '.',\n",
       " 'spin',\n",
       " 'axi',\n",
       " '27.3',\n",
       " 'day',\n",
       " 'star',\n",
       " 'name',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'first',\n",
       " 'one',\n",
       " 'set',\n",
       " 'foot',\n",
       " 'moon',\n",
       " '21',\n",
       " 'juli',\n",
       " '1969',\n",
       " 'reach',\n",
       " 'moon',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'name',\n",
       " 'apollo',\n",
       " 'ii',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d081955",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_without_punctuation=[]\n",
    "for word in lemmatized_word:\n",
    "    if word.isalpha():\n",
    "        words_without_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bd7ffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moon',\n",
       " 'barren',\n",
       " 'rocky',\n",
       " 'world',\n",
       " 'without',\n",
       " 'air',\n",
       " 'water',\n",
       " 'dark',\n",
       " 'lava',\n",
       " 'plain',\n",
       " 'surface',\n",
       " 'moon',\n",
       " 'filled',\n",
       " 'wit',\n",
       " 'crater',\n",
       " 'light',\n",
       " 'get',\n",
       " 'light',\n",
       " 'sun',\n",
       " 'moo',\n",
       " 'keep',\n",
       " 'changing',\n",
       " 'shape',\n",
       " 'move',\n",
       " 'round',\n",
       " 'earth',\n",
       " 'spin',\n",
       " 'axis',\n",
       " 'day',\n",
       " 'star',\n",
       " 'named',\n",
       " 'edwin',\n",
       " 'aldrin',\n",
       " 'first',\n",
       " 'one',\n",
       " 'set',\n",
       " 'foot',\n",
       " 'moon',\n",
       " 'july',\n",
       " 'reached',\n",
       " 'moon',\n",
       " 'space',\n",
       " 'craft',\n",
       " 'named',\n",
       " 'apollo',\n",
       " 'ii']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_without_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af107dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/vishakha/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "pos_tag=nltk.pos_tag(words_without_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38fad2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('moon', 'NN'),\n",
       " ('barren', 'NNS'),\n",
       " ('rocky', 'JJ'),\n",
       " ('world', 'NN'),\n",
       " ('without', 'IN'),\n",
       " ('air', 'NN'),\n",
       " ('water', 'NN'),\n",
       " ('dark', 'NN'),\n",
       " ('lava', 'NN'),\n",
       " ('plain', 'NN'),\n",
       " ('surface', 'NN'),\n",
       " ('moon', 'NN'),\n",
       " ('filled', 'VBD'),\n",
       " ('wit', 'JJ'),\n",
       " ('crater', 'NN'),\n",
       " ('light', 'JJ'),\n",
       " ('get', 'VB'),\n",
       " ('light', 'JJ'),\n",
       " ('sun', 'NN'),\n",
       " ('moo', 'NN'),\n",
       " ('keep', 'VB'),\n",
       " ('changing', 'VBG'),\n",
       " ('shape', 'NN'),\n",
       " ('move', 'NN'),\n",
       " ('round', 'NN'),\n",
       " ('earth', 'NN'),\n",
       " ('spin', 'JJ'),\n",
       " ('axis', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('star', 'NN'),\n",
       " ('named', 'VBN'),\n",
       " ('edwin', 'NN'),\n",
       " ('aldrin', 'NN'),\n",
       " ('first', 'RB'),\n",
       " ('one', 'CD'),\n",
       " ('set', 'NN'),\n",
       " ('foot', 'NN'),\n",
       " ('moon', 'NN'),\n",
       " ('july', 'NN'),\n",
       " ('reached', 'VBD'),\n",
       " ('moon', 'JJ'),\n",
       " ('space', 'NN'),\n",
       " ('craft', 'NN'),\n",
       " ('named', 'VBN'),\n",
       " ('apollo', 'IN'),\n",
       " ('ii', 'NN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0eee3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c9a17cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d0='data science is one of the most important fields of science'\n",
    "d1='this is one of the best data science courses'\n",
    "d2='data scientists analyze data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a088451",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [d0,d1,d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ad7a79f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science is one of the most important fields of science',\n",
       " 'this is one of the best data science courses',\n",
       " 'data scientists analyze data']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e8678b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the corpus: 14\n"
     ]
    }
   ],
   "source": [
    "words_set = set()\n",
    "\n",
    "for doc in corpus:\n",
    "    words = doc.split(' ')\n",
    "    words_set = words_set.union(set(words))\n",
    "    #words_set = set(corpus).union(set(words))\n",
    "    \n",
    "print('Number of words in the corpus:',len(words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "25f1ea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words in the corpus: \n",
      " {'best', 'analyze', 'most', 'scientists', 'important', 'this', 'fields', 'science', 'the', 'of', 'courses', 'data', 'one', 'is'}\n"
     ]
    }
   ],
   "source": [
    "print('The words in the corpus: \\n', words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "745c60c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>analyze</th>\n",
       "      <th>most</th>\n",
       "      <th>scientists</th>\n",
       "      <th>important</th>\n",
       "      <th>this</th>\n",
       "      <th>fields</th>\n",
       "      <th>science</th>\n",
       "      <th>the</th>\n",
       "      <th>of</th>\n",
       "      <th>courses</th>\n",
       "      <th>data</th>\n",
       "      <th>one</th>\n",
       "      <th>is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       best  analyze      most  scientists  important      this    fields  \\\n",
       "0  0.000000     0.00  0.090909        0.00   0.090909  0.000000  0.090909   \n",
       "1  0.111111     0.00  0.000000        0.00   0.000000  0.111111  0.000000   \n",
       "2  0.000000     0.25  0.000000        0.25   0.000000  0.000000  0.000000   \n",
       "\n",
       "    science       the        of   courses      data       one        is  \n",
       "0  0.181818  0.090909  0.181818  0.000000  0.090909  0.090909  0.090909  \n",
       "1  0.111111  0.111111  0.111111  0.111111  0.111111  0.111111  0.111111  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.500000  0.000000  0.000000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_docs = len(corpus)         #·Number of documents in the corpus\n",
    "n_words_set = len(words_set) #·Number of unique words in the \n",
    "\n",
    "df_tf = pd.DataFrame(np.zeros((n_docs, n_words_set)), columns=words_set)\n",
    "\n",
    "# Compute Term Frequency (TF)\n",
    "for i in range(n_docs):\n",
    "    words = corpus[i].split(' ') # Words in the document\n",
    "    for w in words:\n",
    "        df_tf[w][i] = df_tf[w][i] + (1 / len(words))\n",
    "        \n",
    "df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a336c91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF of: \n",
      "           best: 0.47712125471966244\n",
      "        analyze: 0.47712125471966244\n",
      "           most: 0.47712125471966244\n",
      "     scientists: 0.47712125471966244\n",
      "      important: 0.47712125471966244\n",
      "           this: 0.47712125471966244\n",
      "         fields: 0.47712125471966244\n",
      "        science: 0.17609125905568124\n",
      "            the: 0.17609125905568124\n",
      "             of: 0.17609125905568124\n",
      "        courses: 0.47712125471966244\n",
      "           data:        0.0\n",
      "            one: 0.17609125905568124\n",
      "             is: 0.17609125905568124\n"
     ]
    }
   ],
   "source": [
    "print(\"IDF of: \")\n",
    "\n",
    "idf = {}\n",
    "\n",
    "for w in words_set:\n",
    "    k = 0    # number of documents in the corpus that contain this word\n",
    "    \n",
    "    for i in range(n_docs):\n",
    "        if w in corpus[i].split():\n",
    "            k += 1\n",
    "            \n",
    "    idf[w] =  np.log10(n_docs / k)\n",
    "    \n",
    "    print(f'{w:>15}: {idf[w]:>10}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dc10c741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>analyze</th>\n",
       "      <th>most</th>\n",
       "      <th>scientists</th>\n",
       "      <th>important</th>\n",
       "      <th>this</th>\n",
       "      <th>fields</th>\n",
       "      <th>science</th>\n",
       "      <th>the</th>\n",
       "      <th>of</th>\n",
       "      <th>courses</th>\n",
       "      <th>data</th>\n",
       "      <th>one</th>\n",
       "      <th>is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.016008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       best  analyze      most  scientists  important      this    fields  \\\n",
       "0  0.000000  0.00000  0.043375     0.00000   0.043375  0.000000  0.043375   \n",
       "1  0.053013  0.00000  0.000000     0.00000   0.000000  0.053013  0.000000   \n",
       "2  0.000000  0.11928  0.000000     0.11928   0.000000  0.000000  0.000000   \n",
       "\n",
       "    science       the        of   courses  data       one        is  \n",
       "0  0.032017  0.016008  0.032017  0.000000   0.0  0.016008  0.016008  \n",
       "1  0.019566  0.019566  0.019566  0.053013   0.0  0.019566  0.019566  \n",
       "2  0.000000  0.000000  0.000000  0.000000   0.0  0.000000  0.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf = df_tf.copy()\n",
    "\n",
    "for w in words_set:\n",
    "    for i in range(n_docs):\n",
    "        df_tf_idf[w][i] = df_tf[w][i] * idf[w]\n",
    "        \n",
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53ab08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
